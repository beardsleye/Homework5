---
title: "caretPackage"
format: html
---

# Task 1
1. We cross validate to ensure accuracy when fitting the model with random forest model. There for allowing us to find the best subset of predictors.
2. First, you create a boot strap sample. Next, train the tree on this sample. Then, repeat this 10,000 times. Lastly, average across the trees to decrease variance. Then, use the OOB observations to find a prediction error.
3. A general linear model is used for a continuous response that allows for both continuous and categorical predictors.
4. Allowing an interaction term allows for relationships between variables to be accounted for in the model.
5. We split our data into the train and test set to properly fit our model. The training set is for fitting the model, where the test set is to test the performance of the fit.

# Task 2
## EDA and Data Prep
```{r EDA and data prep}
library(readr)
library(tidyverse)
library(psych)
library(caret)

#read in data and make HeartDisease a factor
heart <- read_csv("C:/Users/beard/Downloads/heart.csv")
heart_df<-as_tibble(heart) |>
  mutate( ,HeartDisease = as.factor(HeartDisease))
heart_df

#Show missing counts, find none
na_counts<- colSums(is.na(heart_df))
na_counts

#Summarize numeric variables
heart_df |>
  select(c(Age, RestingBP, Cholesterol, FastingBS, MaxHR, Oldpeak)) |>
  describe()

#Plot correlations between numeric variables
heart_df |>
  select(c(Age, RestingBP, Cholesterol, FastingBS, MaxHR, Oldpeak)) |>
  pairs()

#Following looks at contingency tables of categorical variables and Heart Disease
heart_df |>
  group_by(HeartDisease, Sex) |>
  summarize(count = n()) |>
  pivot_wider(names_from = Sex, values_from = count)

heart_df |>
  group_by(HeartDisease, ChestPainType) |>
  summarize(count = n()) |>
  pivot_wider(names_from = ChestPainType, values_from = count)

heart_df |>
  group_by(HeartDisease, RestingECG) |>
  summarize(count = n()) |>
  pivot_wider(names_from = RestingECG, values_from = count)

heart_df |>
  group_by(HeartDisease, ExerciseAngina) |>
  summarize(count = n()) |>
  pivot_wider(names_from = ExerciseAngina, values_from = count)

heart_df |>
  group_by(HeartDisease, ST_Slope) |>
  summarize(count = n()) |>
  pivot_wider(names_from = ST_Slope, values_from = count)

#Create dummy variables
dummies<-dummyVars(HeartDisease~., data = heart_df) 
dummy_vars<-predict(dummies, newdata = heart_df)
dummy_vars<-as.data.frame(dummy_vars)
dummy_vars

#Remove ST_Slope variables
dummy_vars<-dummy_vars |>
  select(!c(starts_with("ST_Slope")))

#Create tibble with all variables
heart_vars<-cbind("HeartDisease"=heart_df$HeartDisease, dummy_vars)
heart_vars
```
##Split data and KNN
```{r Split and KNN}
library(class)
library(randomForest)
set.seed(66)

#create train and test sets
train <- sample(1:nrow(heart_vars), size = nrow(heart_vars)*0.8)
test <- setdiff(1:nrow(heart_vars), train)

heart_train<-heart_vars[train, ]
heart_test<-heart_vars[test, ]

#do KNN
knn_fit<-train(HeartDisease~Age+RestingBP+Cholesterol+FastingBS+MaxHR+Oldpeak, data=heart_train,
               trControl=trainControl(method = "repeatedcv", number = 10, repeats = 3),
               tuneGrid=expand.grid(k=seq(from = 1, to = 40, by = 1)))

#confusion matrix
test_pred<-predict(knn_fit, newdata=heart_test)
confusionMatrix(test_pred, heart_test$HeartDisease)
```
## Logistic Regression
```{r}
#Select 3 different logistic regressions using EDA as insight
glm1_fit<-train(HeartDisease~., data=heart_train, method= "glm", family="binomial",trControl=trainControl(method = "repeatedcv", number = 10, repeats = 3),
               tuneGrid=expand.grid(k=seq(from = 1, to = 40, by = 1)))

glm2_fit<-train(HeartDisease~.+Age:MaxHR, data=heart_train, method= "glm", family="binomial",trControl=trainControl(method = "repeatedcv", number = 10, repeats = 3),
               tuneGrid=expand.grid(k=seq(from = 1, to = 40, by = 1)))

glm3_fit<-train(HeartDisease~.+SexM:Cholesterol, data=heart_train, method= "glm", family="binomial",trControl=trainControl(method = "repeatedcv", number = 10, repeats = 3),
               tuneGrid=expand.grid(k=seq(from = 1, to = 40, by = 1)))

#create table of results to find best model
results<-rbind(c("glm1", glm1_fit$results[c("RMSE", "Rsquared", "MAE")]),
               c("glm2", glm2_fit$results[c("RMSE", "Rsquared", "MAE")]),
               c("glm3", glm3_fit$results[c("RMSE", "Rsquared", "MAE")]))

results

#print summary of best model
best_model_summary<-summary()
best_model_summary

#confusion matrix for best model
test_pred_glm<-predict(, newdata=heart_test)
confusionMatrix(test_pred_glm, heart_test$HeartDisease)
```
## Tree Models
```{r}
library(tree)
#classification trees
class_tree<-train(HeartDisease~., data=heart_train, method="rpart",
                  trControl=trainControl(method = "cv", number = 10),
                  tuneGrid=expand.grid(cp = seq(0, 0.1, by = 0.001)))

#random forest
random_forest<-train(HeartDisease~., data=heart_train, method="rf",
                  trControl=trainControl(method = "cv", number = 10),
                  tuneGrid=expand.grid(mtry = 1:ncol(heart_train)-1))

#boosted tree
boost_tree<-train(HeartDisease~., data=heart_train, method="gmb", n.trees= c(25,50,100,200),
                  interaction.depth=c(1,2,3),
                  shirinkage=.1,
                  nminobinssode=10,
                  trControl=trainControl(method = "cv", number = 10), verbose = FALSE,
                  tuneGrid=expand.grid())

#classification trees confusion matrix
test_pred_class<-predict(, newdata=heart_test)
confusionMatrix(test_pred_class, heart_test$HeartDisease)

#random forest confusion matrix
test_pred_rf<-predict(, newdata=heart_test)
confusionMatrix(test_pred_rf, heart_test$HeartDisease)

#boosted trees confusion matrix
test_pred_bf<-predict(, newdata=heart_test)
confusionMatrix(test_pred_bf, heart_test$HeartDisease)

```

